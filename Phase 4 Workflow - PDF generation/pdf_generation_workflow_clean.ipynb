{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PDF Generation Workflow - Cleaned Version\n",
        "\n",
        "This notebook processes resume-job matches and generates PDFs for different treatment types.\n",
        "\n",
        "## Features:\n",
        "- Configurable number of files to process\n",
        "- Loops through all treatment types (control, Type_I, Type_II, Type_III)\n",
        "- Saves output PDF links to CSV with all initial data\n",
        "- Appends new records when running again\n",
        "\n",
        "## Configuration:\n",
        "- Set `num_files_to_process` to control how many files to process\n",
        "- Set `test_url` and `authorization` for the API endpoint\n",
        "- Results are saved to `pdf_generation_results.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time  # Add this line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "- Files to process: 1\n",
            "- Treatment types: ['Type_II', 'Type_III']\n",
            "- Output CSV: pdf_generation_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "num_files_to_process = 1  # Set this to control how many files to process\n",
        "test_url = \"https://prayag-is-dummy.app.n8n.cloud/webhook/9eb0c4bc-f2a4-4f23-bb71-26422deedf55\"\n",
        "authorization = (\"prayag_purohit\", \"Resumeaudit\")\n",
        "output_csv = \"pdf_generation_results.csv\"\n",
        "\n",
        "# Treatment types to process\n",
        "treatment_types = ['Type_II', 'Type_III'] # ['control', 'Type_I', 'Type_II', 'Type_III']\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"- Files to process: {num_files_to_process}\")\n",
        "print(f\"- Treatment types: {treatment_types}\")\n",
        "print(f\"- Output CSV: {output_csv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1226 job matches\n",
            "Columns: ['_id', 'job_posting_id', 'title', 'job_description', 'file_id', 'key_metrics.basics.likely_home_country', 'match_score', 'location', 'date_posted']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>job_posting_id</th>\n",
              "      <th>title</th>\n",
              "      <th>job_description</th>\n",
              "      <th>file_id</th>\n",
              "      <th>key_metrics.basics.likely_home_country</th>\n",
              "      <th>match_score</th>\n",
              "      <th>location</th>\n",
              "      <th>date_posted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68a29ca54105e44264b851f7</td>\n",
              "      <td>689d5acce78d625301071376</td>\n",
              "      <td>Database Developer (Software Developer)</td>\n",
              "      <td>Job Description\\nDatabase Developer\\nThis is a...</td>\n",
              "      <td>ITC resume 20.pdf</td>\n",
              "      <td>India</td>\n",
              "      <td>90</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68a29cf6ff6560afd37a01a3</td>\n",
              "      <td>689d5acce78d62530107137b</td>\n",
              "      <td>Application Developer, D365 Finance &amp; Operations</td>\n",
              "      <td>Sporting Life Group is a proudly Canadian fami...</td>\n",
              "      <td>ITC resume 14.pdf</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>75</td>\n",
              "      <td>Vaughan, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68a29cf7ff6560afd37a01a4</td>\n",
              "      <td>689d5acce78d62530107137c</td>\n",
              "      <td>Backend Developer (Python)</td>\n",
              "      <td>**Please note before applying:**  \\n\\n* We’re ...</td>\n",
              "      <td>ITC resume 18.pdf</td>\n",
              "      <td>Eritrea</td>\n",
              "      <td>92</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>68a29d01ff6560afd37a01a6</td>\n",
              "      <td>689d5acce78d62530107137d</td>\n",
              "      <td>Full Stack Developer</td>\n",
              "      <td>**Please note before applying:**  \\n\\n* We’re ...</td>\n",
              "      <td>ITC resume 18.pdf</td>\n",
              "      <td>Eritrea</td>\n",
              "      <td>90</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>68a29d1aff6560afd37a01ad</td>\n",
              "      <td>689d5acce78d625301071389</td>\n",
              "      <td>QA Automation Developer– Java, Selenium, Sales...</td>\n",
              "      <td>**Role Description:**\\n\\n* Java, Selenium, Cuc...</td>\n",
              "      <td>ITC resume 09.pdf</td>\n",
              "      <td>Pakistan</td>\n",
              "      <td>92</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id            job_posting_id  \\\n",
              "0  68a29ca54105e44264b851f7  689d5acce78d625301071376   \n",
              "1  68a29cf6ff6560afd37a01a3  689d5acce78d62530107137b   \n",
              "2  68a29cf7ff6560afd37a01a4  689d5acce78d62530107137c   \n",
              "3  68a29d01ff6560afd37a01a6  689d5acce78d62530107137d   \n",
              "4  68a29d1aff6560afd37a01ad  689d5acce78d625301071389   \n",
              "\n",
              "                                               title  \\\n",
              "0            Database Developer (Software Developer)   \n",
              "1   Application Developer, D365 Finance & Operations   \n",
              "2                         Backend Developer (Python)   \n",
              "3                               Full Stack Developer   \n",
              "4  QA Automation Developer– Java, Selenium, Sales...   \n",
              "\n",
              "                                     job_description            file_id  \\\n",
              "0  Job Description\\nDatabase Developer\\nThis is a...  ITC resume 20.pdf   \n",
              "1  Sporting Life Group is a proudly Canadian fami...  ITC resume 14.pdf   \n",
              "2  **Please note before applying:**  \\n\\n* We’re ...  ITC resume 18.pdf   \n",
              "3  **Please note before applying:**  \\n\\n* We’re ...  ITC resume 18.pdf   \n",
              "4  **Role Description:**\\n\\n* Java, Selenium, Cuc...  ITC resume 09.pdf   \n",
              "\n",
              "  key_metrics.basics.likely_home_country  match_score         location  \\\n",
              "0                                  India           90  Toronto, ON, CA   \n",
              "1                           Saudi Arabia           75  Vaughan, ON, CA   \n",
              "2                                Eritrea           92  Toronto, ON, CA   \n",
              "3                                Eritrea           90  Toronto, ON, CA   \n",
              "4                               Pakistan           92  Toronto, ON, CA   \n",
              "\n",
              "  date_posted  \n",
              "0  2025-08-13  \n",
              "1  2025-08-13  \n",
              "2  2025-08-13  \n",
              "3  2025-08-13  \n",
              "4  2025-08-13  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the job matches data\n",
        "file_path = \"Resume_study.resume_job_matches_filtered.csv\"\n",
        "job_matches_df = pd.read_csv(file_path)\n",
        "\n",
        "# Rename columns to match our endpoint requirements\n",
        "job_matches_df.rename(\n",
        "    columns={\n",
        "        'description': 'job_description',\n",
        "        'tile': 'job_title'\n",
        "    }, inplace=True)\n",
        "\n",
        "print(f\"Loaded {len(job_matches_df)} job matches\")\n",
        "print(f\"Columns: {list(job_matches_df.columns)}\")\n",
        "job_matches_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique files: 18\n",
            "Files to process:\n",
            "  ITC resume 20.pdf\n"
          ]
        }
      ],
      "source": [
        "# Get unique files to process\n",
        "unique_files_df = job_matches_df.drop_duplicates(subset='file_id')\n",
        "print(f\"Total unique files: {len(unique_files_df)}\")\n",
        "\n",
        "# Limit to the number of files specified in configuration\n",
        "files_to_process = unique_files_df.head(num_files_to_process)\n",
        "print(f\"Files to process:\")\n",
        "for idx, row in files_to_process.iterrows():\n",
        "    print(f\"  {row['file_id']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 20 existing results from pdf_generation_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Load existing results if available\n",
        "existing_results = []\n",
        "if os.path.exists(output_csv):\n",
        "    existing_results = pd.read_csv(output_csv).to_dict('records')\n",
        "    print(f\"Loaded {len(existing_results)} existing results from {output_csv}\")\n",
        "else:\n",
        "    print(f\"No existing results found. Will create new {output_csv}\")\n",
        "\n",
        "# Initialize results list\n",
        "new_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting processing of 2 operations...\n",
            "============================================================\n",
            "\n",
            "Processing file 1/1: ITC resume 20.pdf\n",
            "----------------------------------------\n",
            "  Treatment 1/2: Type_II\n",
            "    📤 Sending request for Type_II...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    📤 Sending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtreatment_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauthorization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     48\u001b[39m     response_data = response.json()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\n01780947\\OneDrive - Humber Polytechnic\\Documents\\Repos\\resume_parsing_audit_study\\.venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Process each file with each treatment type\n",
        "total_operations = len(files_to_process) * len(treatment_types)\n",
        "current_operation = 0\n",
        "stop_processing = False\n",
        "\n",
        "print(f\"Starting processing of {total_operations} operations...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for file_idx, (_, file_row) in enumerate(files_to_process.iterrows()):\n",
        "    if stop_processing:\n",
        "        break\n",
        "    \n",
        "    print(f\"\\nProcessing file {file_idx + 1}/{len(files_to_process)}: {file_row['file_id']}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for treatment_idx, treatment_type in enumerate(treatment_types):\n",
        "        if stop_processing:\n",
        "            break\n",
        "            \n",
        "        current_operation += 1\n",
        "        print(f\"  Treatment {treatment_idx + 1}/{len(treatment_types)}: {treatment_type}\")\n",
        "        \n",
        "        try:\n",
        "            # Create request body\n",
        "            request_body = file_row.to_dict()\n",
        "            request_body['treatment_type'] = treatment_type\n",
        "            \n",
        "            # Add required fields if not present\n",
        "            if 'name' not in request_body:\n",
        "                request_body['name'] = 'Test User'\n",
        "            if 'email' not in request_body:\n",
        "                request_body['email'] = 'test@example.com'\n",
        "            if 'phone' not in request_body:\n",
        "                request_body['phone'] = '123-456-7890'\n",
        "            \n",
        "            # Add location from the job posting\n",
        "            if 'location' in request_body and pd.notna(request_body['location']) and request_body['location'].strip():\n",
        "                pass\n",
        "            else:\n",
        "                # Fallback if location is missing\n",
        "                request_body['location'] = 'Toronto, ON'\n",
        "            \n",
        "            # Send request\n",
        "            print(f\"    📤 Sending request for {treatment_type}...\")\n",
        "            response = requests.post(test_url, json=request_body, auth=authorization)\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                response_data = response.json()\n",
        "                \n",
        "                # Extract PDF link\n",
        "                if 'webViewLink' in response_data:\n",
        "                    pdf_link = response_data['webViewLink']\n",
        "                    download_link = response_data.get('webContentLink', '')\n",
        "                    file_id = response_data.get('id', '')\n",
        "                else:\n",
        "                    # Fallback for older API response format\n",
        "                    pdf_link = response_data.get('download_url', '')\n",
        "                    download_link = ''\n",
        "                    file_id = ''\n",
        "                \n",
        "                # Create result record\n",
        "                result_record = {\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                    'file_id': file_row['file_id'],\n",
        "                    'treatment_type': treatment_type,\n",
        "                    'pdf_link': pdf_link,\n",
        "                    'download_link': download_link,\n",
        "                    'google_drive_id': file_id,\n",
        "                    'status': 'success',\n",
        "                    'response_status': response.status_code\n",
        "                }\n",
        "                \n",
        "                # Add all original data from the file row\n",
        "                for col, value in file_row.items():\n",
        "                    if col not in result_record:\n",
        "                        result_record[col] = value\n",
        "                \n",
        "                new_results.append(result_record)\n",
        "                print(f\"    ✓ Success: {pdf_link}\")\n",
        "                \n",
        "            else:\n",
        "                print(f\"    ✗ Failed: HTTP {response.status_code}\")\n",
        "                \n",
        "                # Check if it's a 404 error and stop processing\n",
        "                if response.status_code == 404:\n",
        "                    print(f\"    �� 404 Error detected. Stopping all processing.\")\n",
        "                    print(f\"    Last processed: File {file_row['file_id']}, Treatment {treatment_type}\")\n",
        "                    \n",
        "                    # Create error record for the failed operation\n",
        "                    result_record = {\n",
        "                        'timestamp': datetime.now().isoformat(),\n",
        "                        'file_id': file_row['file_id'],\n",
        "                        'treatment_type': treatment_type,\n",
        "                        'pdf_link': '',\n",
        "                        'download_link': '',\n",
        "                        'google_drive_id': '',\n",
        "                        'status': 'failed_404_stopped',\n",
        "                        'response_status': response.status_code,\n",
        "                        'error_message': response.text\n",
        "                    }\n",
        "                    \n",
        "                    # Add all original data from the file row\n",
        "                    for col, value in file_row.items():\n",
        "                        if col not in result_record:\n",
        "                            result_record[col] = value\n",
        "                    \n",
        "                    new_results.append(result_record)\n",
        "                    \n",
        "                    # Set flag to stop processing and break out of inner loop\n",
        "                    stop_processing = True\n",
        "                    break\n",
        "                \n",
        "                # Create error record for other HTTP errors\n",
        "                result_record = {\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                    'file_id': file_row['file_id'],\n",
        "                    'treatment_type': treatment_type,\n",
        "                    'pdf_link': '',\n",
        "                    'download_link': '',\n",
        "                    'google_drive_id': '',\n",
        "                    'status': 'failed',\n",
        "                    'response_status': response.status_code,\n",
        "                    'error_message': response.text\n",
        "                }\n",
        "                \n",
        "                # Add all original data from the file row\n",
        "                for col, value in file_row.items():\n",
        "                    if col not in result_record:\n",
        "                        result_record[col] = value\n",
        "                \n",
        "                new_results.append(result_record)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"    ✗ Error: {str(e)}\")\n",
        "            \n",
        "            # Create error record\n",
        "            result_record = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'file_id': file_row['file_id'],\n",
        "                'treatment_type': treatment_type,\n",
        "                'pdf_link': '',\n",
        "                'download_link': '',\n",
        "                'google_drive_id': '',\n",
        "                'status': 'error',\n",
        "                'response_status': '',\n",
        "                'error_message': str(e)\n",
        "            }\n",
        "            \n",
        "            # Add all original data from the file row\n",
        "            for col, value in file_row.items():\n",
        "                if col not in result_record:\n",
        "                    result_record[col] = value\n",
        "            \n",
        "            new_results.append(result_record)\n",
        "        \n",
        "        # Progress update\n",
        "        print(f\"    Progress: {current_operation}/{total_operations} ({current_operation/total_operations*100:.1f}%)\")\n",
        "        \n",
        "        # Add delay between requests to avoid overwhelming n8n\n",
        "        if not stop_processing:\n",
        "            print(f\"    ⏳ Waiting 3 seconds before next request...\")\n",
        "            time.sleep(3)  # Wait 3 seconds between requests\n",
        "            print(f\"    ▶️ Continuing to next request...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"Processing completed! Generated {len(new_results)} new results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to pdf_generation_results.csv\n",
            "Total records: 23\n",
            "New records added: 3\n",
            "\n",
            "Summary:\n",
            "- Success: 22\n",
            "- Failed: 0\n",
            "- Errors: 0\n",
            "\n",
            "First few results:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>file_id</th>\n",
              "      <th>treatment_type</th>\n",
              "      <th>status</th>\n",
              "      <th>pdf_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-08-21T16:04:46.491375</td>\n",
              "      <td>ITC resume 17.pdf</td>\n",
              "      <td>control</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/10ViuPPxuSPlJW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-08-21T16:05:34.696647</td>\n",
              "      <td>ITC resume 17.pdf</td>\n",
              "      <td>Type_I</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/17Kauj7gr9FMsK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-08-21T16:06:28.159364</td>\n",
              "      <td>ITC resume 17.pdf</td>\n",
              "      <td>Type_II</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/1QaIJkJtlyUnKM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-08-21T16:07:23.891111</td>\n",
              "      <td>ITC resume 17.pdf</td>\n",
              "      <td>Type_III</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/18fqIcoDfwJtdf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-08-21T16:07:57.974356</td>\n",
              "      <td>ITC resume 20.pdf</td>\n",
              "      <td>control</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/1htQ7xeqqF55UZ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-08-21T16:08:37.520049</td>\n",
              "      <td>ITC resume 20.pdf</td>\n",
              "      <td>Type_I</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/1Sj5xheRcx7tiB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-08-21T16:09:10.207873</td>\n",
              "      <td>ITC resume 20.pdf</td>\n",
              "      <td>Type_II</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/1N_k-6EjZeS69_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-08-21T16:09:50.551174</td>\n",
              "      <td>ITC resume 20.pdf</td>\n",
              "      <td>Type_III</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/17NsJuWDKhz72H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-08-21T16:10:42.449092</td>\n",
              "      <td>ITC resume 14.pdf</td>\n",
              "      <td>control</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/1pMgRmrNGNYecA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-08-21T16:11:31.783429</td>\n",
              "      <td>ITC resume 14.pdf</td>\n",
              "      <td>Type_I</td>\n",
              "      <td>success</td>\n",
              "      <td>https://drive.google.com/file/d/11uswsbbAnXnrX...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    timestamp            file_id treatment_type   status  \\\n",
              "0  2025-08-21T16:04:46.491375  ITC resume 17.pdf        control  success   \n",
              "1  2025-08-21T16:05:34.696647  ITC resume 17.pdf         Type_I  success   \n",
              "2  2025-08-21T16:06:28.159364  ITC resume 17.pdf        Type_II  success   \n",
              "3  2025-08-21T16:07:23.891111  ITC resume 17.pdf       Type_III  success   \n",
              "4  2025-08-21T16:07:57.974356  ITC resume 20.pdf        control  success   \n",
              "5  2025-08-21T16:08:37.520049  ITC resume 20.pdf         Type_I  success   \n",
              "6  2025-08-21T16:09:10.207873  ITC resume 20.pdf        Type_II  success   \n",
              "7  2025-08-21T16:09:50.551174  ITC resume 20.pdf       Type_III  success   \n",
              "8  2025-08-21T16:10:42.449092  ITC resume 14.pdf        control  success   \n",
              "9  2025-08-21T16:11:31.783429  ITC resume 14.pdf         Type_I  success   \n",
              "\n",
              "                                            pdf_link  \n",
              "0  https://drive.google.com/file/d/10ViuPPxuSPlJW...  \n",
              "1  https://drive.google.com/file/d/17Kauj7gr9FMsK...  \n",
              "2  https://drive.google.com/file/d/1QaIJkJtlyUnKM...  \n",
              "3  https://drive.google.com/file/d/18fqIcoDfwJtdf...  \n",
              "4  https://drive.google.com/file/d/1htQ7xeqqF55UZ...  \n",
              "5  https://drive.google.com/file/d/1Sj5xheRcx7tiB...  \n",
              "6  https://drive.google.com/file/d/1N_k-6EjZeS69_...  \n",
              "7  https://drive.google.com/file/d/17NsJuWDKhz72H...  \n",
              "8  https://drive.google.com/file/d/1pMgRmrNGNYecA...  \n",
              "9  https://drive.google.com/file/d/11uswsbbAnXnrX...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine existing and new results\n",
        "all_results = existing_results + new_results\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv(output_csv, index=False)\n",
        "print(f\"Results saved to {output_csv}\")\n",
        "print(f\"Total records: {len(results_df)}\")\n",
        "print(f\"New records added: {len(new_results)}\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"- Success: {len(results_df[results_df['status'] == 'success'])}\")\n",
        "print(f\"- Failed: {len(results_df[results_df['status'] == 'failed'])}\")\n",
        "print(f\"- Errors: {len(results_df[results_df['status'] == 'error'])}\")\n",
        "\n",
        "# Show first few results\n",
        "print(\"\\nFirst few results:\")\n",
        "results_df[['timestamp', 'file_id', 'treatment_type', 'status', 'pdf_link']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detailed results for the first processed file:\n",
            "\n",
            "Treatment: control\n",
            "Status: success\n",
            "PDF Link: https://drive.google.com/file/d/1htQ7xeqqF55UZcknz6nfFlZBVjC6Reo4/view?usp=drivesdk\n",
            "\n",
            "Treatment: Type_I\n",
            "Status: success\n",
            "PDF Link: https://drive.google.com/file/d/1Sj5xheRcx7tiBx3hsQgAyGKanar05svt/view?usp=drivesdk\n",
            "\n",
            "Treatment: Type_II\n",
            "Status: success\n",
            "PDF Link: https://drive.google.com/file/d/1N_k-6EjZeS69_n66LlWK0yPZRKlF_juJ/view?usp=drivesdk\n",
            "\n",
            "Treatment: Type_III\n",
            "Status: success\n",
            "PDF Link: https://drive.google.com/file/d/17NsJuWDKhz72HB5GhitlFdc-QQ3wPMsd/view?usp=drivesdk\n",
            "\n",
            "Treatment: Type_II\n",
            "Status: failed_404_stopped\n",
            "Error: {\"code\":404,\"message\":\"The requested webhook \\\"POST 9eb0c4bc-f2a4-4f23-bb71-26422deedf55\\\" is not registered.\",\"hint\":\"The workflow must be active for a production URL to run successfully. You can activate the workflow using the toggle in the top-right of the editor. Note that unlike test URL calls, production URL calls aren't shown on the canvas (only in the executions list)\"}\n",
            "\n",
            "Treatment: Type_II\n",
            "Status: success\n",
            "PDF Link: \n",
            "\n",
            "Treatment: Type_III\n",
            "Status: success\n",
            "PDF Link: \n"
          ]
        }
      ],
      "source": [
        "# Optional: Display detailed results for a specific file\n",
        "if len(new_results) > 0:\n",
        "    print(\"Detailed results for the first processed file:\")\n",
        "    first_file_id = new_results[0]['file_id']\n",
        "    file_results = results_df[results_df['file_id'] == first_file_id]\n",
        "    \n",
        "    for _, row in file_results.iterrows():\n",
        "        print(f\"\\nTreatment: {row['treatment_type']}\")\n",
        "        print(f\"Status: {row['status']}\")\n",
        "        if row['status'] == 'success':\n",
        "            print(f\"PDF Link: {row['pdf_link']}\")\n",
        "        else:\n",
        "            print(f\"Error: {row.get('error_message', 'Unknown error')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
