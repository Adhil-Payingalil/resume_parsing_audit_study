{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PDF Generation Workflow - With PII Integration\n",
        "\n",
        "This notebook processes resume-job matches and generates PDFs for different treatment types with enhanced PII (Personally Identifiable Information) data integration.\n",
        "\n",
        "## Features:\n",
        "- **Interactive File Selection**: Choose specific files to process or process all files\n",
        "- **Enhanced PII Generation**: Automatically generates culturally appropriate names, emails, and phone numbers\n",
        "- **Geographic Cluster Mapping**: Maps countries to geographic regions for PII selection\n",
        "- **Treatment Type Support**: Loops through all treatment types (control, Type_I, Type_II, Type_III)\n",
        "- **Enhanced Webhook Integration**: Sends comprehensive PII data to the webhook endpoint\n",
        "- **Comprehensive Logging**: Tracks all PII data used for each request\n",
        "- **Results Management**: Saves output PDF links to CSV with enhanced PII data\n",
        "- **Append Mode**: Adds new records when running again\n",
        "\n",
        "## PII Data Generation:\n",
        "- **Country Mapping**: Automatically maps resume countries to geographic clusters\n",
        "- **Cultural Names**: Generates appropriate first names based on geographic region\n",
        "- **Treatment-Specific Data**: Each treatment type gets unique last names, emails, and phone numbers\n",
        "- **Random Selection**: Randomly selects gender and names for diversity\n",
        "- **Fallback Handling**: Graceful fallback to default values when country data is missing\n",
        "\n",
        "## Configuration:\n",
        "- Set `selection_choice` to control file selection method (1-4)\n",
        "- Configure `file_numbers` or `filenames` for specific file selection\n",
        "- Set `treatment_types` to specify which treatments to process\n",
        "- Set `test_url` and `authorization` for the API endpoint\n",
        "- Results are saved to `pdf_generation_results.csv`\n",
        "\n",
        "## Data Sources:\n",
        "- **Country Mapping**: `Country and Geographic_Cluster Mapping.csv`\n",
        "- **PII Clusters**: `Resume Audit - Country Clusters - Clusters.csv`\n",
        "- **Job Matches**: `Resume_study.resume_job_matches_filtered.csv`\n",
        "\n",
        "## Webhook Integration:\n",
        "The enhanced webhook now receives:\n",
        "- Basic fields: `file_id`, `treatment_type`, `location`\n",
        "- PII fields: `name`, `email`, `phone`, `first_name`, `last_name`, `gender`\n",
        "- Geographic fields: `country`, `geographic_cluster`\n",
        "\n",
        "## Output:\n",
        "Enhanced CSV with all original data plus:\n",
        "- PII information (names, emails, phones)\n",
        "- Geographic clustering data\n",
        "- Treatment-specific identifiers\n",
        "- Complete audit trail of all operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time  # Add this line\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "- Files to process: 5\n",
            "- Treatment types: ['Type_II', 'Type_III']\n",
            "- Output CSV: google_doc_generation_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "num_files_to_process = 5  # Set this to control how many files to process\n",
        "test_url = \"https://prayag-is-dummy.app.n8n.cloud/webhook/9eb0c4bc-f2a4-4f23-bb71-26422deedf55\"\n",
        "authorization = (\"prayag_purohit\", \"Resumeaudit\")\n",
        "output_csv = \"google_doc_generation_results.csv\"\n",
        "\n",
        "# Treatment types to process\n",
        "treatment_types = ['Type_II', 'Type_III'] # ['control', 'Type_I', 'Type_II', 'Type_III']\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"- Files to process: {num_files_to_process}\")\n",
        "print(f\"- Treatment types: {treatment_types}\")\n",
        "print(f\"- Output CSV: {output_csv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1226 job matches\n",
            "Columns: ['_id', 'job_posting_id', 'title', 'job_description', 'file_id', 'key_metrics.basics.likely_home_country', 'match_score', 'location', 'date_posted']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>job_posting_id</th>\n",
              "      <th>title</th>\n",
              "      <th>job_description</th>\n",
              "      <th>file_id</th>\n",
              "      <th>key_metrics.basics.likely_home_country</th>\n",
              "      <th>match_score</th>\n",
              "      <th>location</th>\n",
              "      <th>date_posted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68a29ca54105e44264b851f7</td>\n",
              "      <td>689d5acce78d625301071376</td>\n",
              "      <td>Database Developer (Software Developer)</td>\n",
              "      <td>Job Description\\nDatabase Developer\\nThis is a...</td>\n",
              "      <td>ITC resume 20.pdf</td>\n",
              "      <td>India</td>\n",
              "      <td>90</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68a29cf6ff6560afd37a01a3</td>\n",
              "      <td>689d5acce78d62530107137b</td>\n",
              "      <td>Application Developer, D365 Finance &amp; Operations</td>\n",
              "      <td>Sporting Life Group is a proudly Canadian fami...</td>\n",
              "      <td>ITC resume 14.pdf</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>75</td>\n",
              "      <td>Vaughan, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68a29cf7ff6560afd37a01a4</td>\n",
              "      <td>689d5acce78d62530107137c</td>\n",
              "      <td>Backend Developer (Python)</td>\n",
              "      <td>**Please note before applying:**  \\n\\n* Weâ€™re ...</td>\n",
              "      <td>ITC resume 18.pdf</td>\n",
              "      <td>Eritrea</td>\n",
              "      <td>92</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>68a29d01ff6560afd37a01a6</td>\n",
              "      <td>689d5acce78d62530107137d</td>\n",
              "      <td>Full Stack Developer</td>\n",
              "      <td>**Please note before applying:**  \\n\\n* Weâ€™re ...</td>\n",
              "      <td>ITC resume 18.pdf</td>\n",
              "      <td>Eritrea</td>\n",
              "      <td>90</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>68a29d1aff6560afd37a01ad</td>\n",
              "      <td>689d5acce78d625301071389</td>\n",
              "      <td>QA Automation Developerâ€“ Java, Selenium, Sales...</td>\n",
              "      <td>**Role Description:**\\n\\n* Java, Selenium, Cuc...</td>\n",
              "      <td>ITC resume 09.pdf</td>\n",
              "      <td>Pakistan</td>\n",
              "      <td>92</td>\n",
              "      <td>Toronto, ON, CA</td>\n",
              "      <td>2025-08-13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id            job_posting_id  \\\n",
              "0  68a29ca54105e44264b851f7  689d5acce78d625301071376   \n",
              "1  68a29cf6ff6560afd37a01a3  689d5acce78d62530107137b   \n",
              "2  68a29cf7ff6560afd37a01a4  689d5acce78d62530107137c   \n",
              "3  68a29d01ff6560afd37a01a6  689d5acce78d62530107137d   \n",
              "4  68a29d1aff6560afd37a01ad  689d5acce78d625301071389   \n",
              "\n",
              "                                               title  \\\n",
              "0            Database Developer (Software Developer)   \n",
              "1   Application Developer, D365 Finance & Operations   \n",
              "2                         Backend Developer (Python)   \n",
              "3                               Full Stack Developer   \n",
              "4  QA Automation Developerâ€“ Java, Selenium, Sales...   \n",
              "\n",
              "                                     job_description            file_id  \\\n",
              "0  Job Description\\nDatabase Developer\\nThis is a...  ITC resume 20.pdf   \n",
              "1  Sporting Life Group is a proudly Canadian fami...  ITC resume 14.pdf   \n",
              "2  **Please note before applying:**  \\n\\n* Weâ€™re ...  ITC resume 18.pdf   \n",
              "3  **Please note before applying:**  \\n\\n* Weâ€™re ...  ITC resume 18.pdf   \n",
              "4  **Role Description:**\\n\\n* Java, Selenium, Cuc...  ITC resume 09.pdf   \n",
              "\n",
              "  key_metrics.basics.likely_home_country  match_score         location  \\\n",
              "0                                  India           90  Toronto, ON, CA   \n",
              "1                           Saudi Arabia           75  Vaughan, ON, CA   \n",
              "2                                Eritrea           92  Toronto, ON, CA   \n",
              "3                                Eritrea           90  Toronto, ON, CA   \n",
              "4                               Pakistan           92  Toronto, ON, CA   \n",
              "\n",
              "  date_posted  \n",
              "0  2025-08-13  \n",
              "1  2025-08-13  \n",
              "2  2025-08-13  \n",
              "3  2025-08-13  \n",
              "4  2025-08-13  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the job matches data\n",
        "file_path = \"Resume_study.resume_job_matches_filtered.csv\"\n",
        "job_matches_df = pd.read_csv(file_path)\n",
        "\n",
        "# Rename columns to match our endpoint requirements\n",
        "job_matches_df.rename(\n",
        "    columns={\n",
        "        'description': 'job_description',\n",
        "        'tile': 'job_title'\n",
        "    }, inplace=True)\n",
        "\n",
        "print(f\"Loaded {len(job_matches_df)} job matches\")\n",
        "print(f\"Columns: {list(job_matches_df.columns)}\")\n",
        "job_matches_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Available Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique files: 18\n",
            "\n",
            "Available files to process:\n",
            "------------------------------------------------------------\n",
            " 1. ITC resume 20.pdf\n",
            "    Country: India\n",
            "    Location: Toronto, ON, CA\n",
            "\n",
            " 2. ITC resume 14.pdf\n",
            "    Country: Saudi Arabia\n",
            "    Location: Vaughan, ON, CA\n",
            "\n",
            " 3. ITC resume 18.pdf\n",
            "    Country: Eritrea\n",
            "    Location: Toronto, ON, CA\n",
            "\n",
            " 5. ITC resume 09.pdf\n",
            "    Country: Pakistan\n",
            "    Location: Toronto, ON, CA\n",
            "\n",
            " 6. ITC resume 07.pdf\n",
            "    Country: Turkey\n",
            "    Location: Toronto, ON, CA\n",
            "\n",
            " 7. ITC resume 08.pdf\n",
            "    Country: Mauritius\n",
            "    Location: Toronto, ON, CA\n",
            "\n",
            "11. ITC resume 16.pdf\n",
            "    Country: USA\n",
            "    Location: Toronto, ON, CA\n",
            "\n",
            "18. ITC resume 01.pdf\n",
            "    Country: Lebanon\n",
            "    Location: Vancouver, BC, CA\n",
            "\n",
            "47. ITC resume 17.pdf\n",
            "    Country: India\n",
            "    Location: Calgary, AB, CA\n",
            "\n",
            "67. ITC resume 03.pdf\n",
            "    Country: Bangladesh\n",
            "    Location: Edmonton, AB, CA\n",
            "\n",
            "75. ITC resume 15.pdf\n",
            "    Country: India\n",
            "    Location: Ottawa, ON, CA\n",
            "\n",
            "393. ITC resume 04.pdf\n",
            "    Country: India\n",
            "    Location: Shelburne, ON, CA\n",
            "\n",
            "463. ITC resume 19.pdf\n",
            "    Country: Sri Lanka\n",
            "    Location: Ottawa, ON, CA\n",
            "\n",
            "498. ITC resume 02.pdf\n",
            "    Country: Iran\n",
            "    Location: MontrÃ©al, QC, CA\n",
            "\n",
            "501. ITC resume 05.pdf\n",
            "    Country: Ukraine\n",
            "    Location: Leduc, AB, CA\n",
            "\n",
            "598. ITC resume 12.pdf\n",
            "    Country: India\n",
            "    Location: Winnipeg, MB, CA\n",
            "\n",
            "662. ITC resume 10.pdf\n",
            "    Country: India\n",
            "    Location: Halifax, NS, CA\n",
            "\n",
            "902. ITC resume 13.pdf\n",
            "    Country: Brazil\n",
            "    Location: Richmond, BC, CA\n",
            "\n",
            "File selection options:\n",
            "1. Process all files\n",
            "2. Process specific files by number\n",
            "3. Process specific files by filename\n",
            "4. Process first N files (current behavior)\n"
          ]
        }
      ],
      "source": [
        "# Get unique files to process\n",
        "unique_files_df = job_matches_df.drop_duplicates(subset='file_id')\n",
        "print(f\"Total unique files: {len(unique_files_df)}\")\n",
        "\n",
        "# Display all available files with their details\n",
        "print(\"\\nAvailable files to process:\")\n",
        "print(\"-\" * 60)\n",
        "for idx, row in unique_files_df.iterrows():\n",
        "    print(f\"{idx+1:2d}. {row['file_id']}\")\n",
        "    if 'key_metrics.basics.likely_home_country' in row and pd.notna(row['key_metrics.basics.likely_home_country']):\n",
        "        print(f\"    Country: {row['key_metrics.basics.likely_home_country']}\")\n",
        "    if 'location' in row and pd.notna(row['location']):\n",
        "        print(f\"    Location: {row['location']}\")\n",
        "    print()\n",
        "\n",
        "# File selection options\n",
        "print(\"File selection options:\")\n",
        "print(\"1. Process all files\")\n",
        "print(\"2. Process specific files by number\")\n",
        "print(\"3. Process specific files by filename\")\n",
        "print(\"4. Process first N files (current behavior)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### File Selection and Processing Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing ALL 18 files\n",
            "\n",
            "Final selection: 18 files to process\n"
          ]
        }
      ],
      "source": [
        "# File selection configuration\n",
        "# CHANGE THESE VARIABLES TO SELECT YOUR OPTION\n",
        "\n",
        "selection_choice = \"1\"  # Change to \"1\", \"2\", \"3\", or \"4\"\n",
        "\n",
        "# For option 2 (specific file numbers) - change these to the file numbers you want (1-based indexing)\n",
        "file_numbers = [18]  # Example: process files 1, 3, and 5\n",
        "\n",
        "# For option 3 (specific filenames) - change these to the exact filenames you want\n",
        "filenames = [\"ITC resume 20.pdf\", \"another_file.pdf\"]  # Example filenames\n",
        "\n",
        "# File selection logic\n",
        "if selection_choice == \"1\":\n",
        "    # Process all files\n",
        "    files_to_process = unique_files_df\n",
        "    print(f\"\\nProcessing ALL {len(files_to_process)} files\")\n",
        "    \n",
        "elif selection_choice == \"2\":\n",
        "    # Process specific files by number\n",
        "    print(f\"\\nProcessing specific files by number: {file_numbers}\")\n",
        "    try:\n",
        "        # Convert to 0-based indexing\n",
        "        valid_indices = [i - 1 for i in file_numbers if 1 <= i <= len(unique_files_df)]\n",
        "        if valid_indices:\n",
        "            files_to_process = unique_files_df.iloc[valid_indices]\n",
        "            print(f\"Processing {len(files_to_process)} selected files:\")\n",
        "            for idx, row in files_to_process.iterrows():\n",
        "                print(f\"  {row['file_id']}\")\n",
        "        else:\n",
        "            print(\"No valid file numbers provided. Processing first file.\")\n",
        "            files_to_process = unique_files_df.head(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}. Processing first file.\")\n",
        "        files_to_process = unique_files_df.head(1)\n",
        "        \n",
        "elif selection_choice == \"3\":\n",
        "    # Process specific files by filename\n",
        "    print(f\"\\nProcessing specific files by filename: {filenames}\")\n",
        "    try:\n",
        "        files_to_process = unique_files_df[unique_files_df['file_id'].isin(filenames)]\n",
        "        if len(files_to_process) > 0:\n",
        "            print(f\"Processing {len(files_to_process)} selected files:\")\n",
        "            for idx, row in files_to_process.iterrows():\n",
        "                print(f\"  {row['file_id']}\")\n",
        "        else:\n",
        "            print(\"No matching filenames found. Processing first file.\")\n",
        "            files_to_process = unique_files_df.head(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}. Processing first file.\")\n",
        "        files_to_process = unique_files_df.head(1)\n",
        "        \n",
        "elif selection_choice == \"4\":\n",
        "    # Process first N files (current behavior)\n",
        "    files_to_process = unique_files_df.head(num_files_to_process)\n",
        "    print(f\"\\nProcessing first {num_files_to_process} files:\")\n",
        "    for idx, row in files_to_process.iterrows():\n",
        "        print(f\"  {row['file_id']}\")\n",
        "        \n",
        "else:\n",
        "    # Default to first N files if invalid input\n",
        "    print(\"Invalid choice. Processing first file.\")\n",
        "    files_to_process = unique_files_df.head(1)\n",
        "\n",
        "print(f\"\\nFinal selection: {len(files_to_process)} files to process\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load PII Mapping Data and Setup Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded country mapping: 53 countries mapped to 6 clusters\n",
            "Loaded PII clusters: 24 cluster-treatment combinations\n",
            "\n",
            "PII lookup structure created:\n",
            "  South Asia: ['control', 'Type_I', 'Type_II', 'Type_III']\n",
            "  Sub-Saharan Africa: ['control', 'Type_I', 'Type_II', 'Type_III']\n",
            "  Middle East & North Africa: ['control', 'Type_I', 'Type_II', 'Type_III']\n",
            "  East & Southeast Asia: ['control', 'Type_I', 'Type_II', 'Type_III']\n",
            "  Eastern Europe: ['control', 'Type_I', 'Type_II', 'Type_III']\n",
            "  Latin America: ['control', 'Type_I', 'Type_II', 'Type_III']\n",
            "\n",
            "Testing PII generation:\n",
            "  Country: India, Treatment: Type_II\n",
            "  Generated: Anika Kumar (Female)\n",
            "  Email: kumar.xx@gmail.com\n",
            "  Phone: +1 (647) 333-0003\n"
          ]
        }
      ],
      "source": [
        "# Load the country to geographic cluster mapping\n",
        "country_cluster_df = pd.read_csv(\"Country and Geographic_Cluster Mapping.csv\")\n",
        "print(f\"Loaded country mapping: {len(country_cluster_df)} countries mapped to {country_cluster_df['Geographic_Cluster'].nunique()} clusters\")\n",
        "\n",
        "# Load the PII clusters data\n",
        "pii_clusters_df = pd.read_csv(\"Resume Audit - Country Clusters - Clusters.csv\")\n",
        "print(f\"Loaded PII clusters: {len(pii_clusters_df)} cluster-treatment combinations\")\n",
        "\n",
        "# Create lookup dictionaries for efficient access\n",
        "country_to_cluster = dict(zip(country_cluster_df['Country'], country_cluster_df['Geographic_Cluster']))\n",
        "\n",
        "# Create a nested dictionary for PII lookup: {cluster: {treatment: pii_data}}\n",
        "pii_lookup = {}\n",
        "for _, row in pii_clusters_df.iterrows():\n",
        "    cluster = row['Geographic_Cluster']\n",
        "    treatment = row['Treatment Type']\n",
        "    \n",
        "    if cluster not in pii_lookup:\n",
        "        pii_lookup[cluster] = {}\n",
        "    \n",
        "    # Parse the name pools into lists\n",
        "    male_names = [name.strip() for name in row['Male_First_Name_Pool'].split(',')]\n",
        "    female_names = [name.strip() for name in row['Female_First_Name_Pool'].split(',')]\n",
        "    \n",
        "    pii_lookup[cluster][treatment] = {\n",
        "        'last_name': row['Last_Name'],\n",
        "        'email': row['Assigned_Email'],\n",
        "        'phone': row['Assigned_Phone_Number'],\n",
        "        'male_names': male_names,\n",
        "        'female_names': female_names\n",
        "    }\n",
        "\n",
        "print(f\"\\nPII lookup structure created:\")\n",
        "for cluster in pii_lookup:\n",
        "    print(f\"  {cluster}: {list(pii_lookup[cluster].keys())}\")\n",
        "\n",
        "# Function to get PII data for a country and treatment type\n",
        "def get_pii_data(country, treatment_type):\n",
        "    \"\"\"\n",
        "    Get PII data for a given country and treatment type.\n",
        "    \n",
        "    Args:\n",
        "        country (str): Country name\n",
        "        treatment_type (str): Treatment type (control, Type_I, Type_II, Type_III)\n",
        "    \n",
        "    Returns:\n",
        "        dict: PII data with keys: last_name, email, phone, male_names, female_names\n",
        "        None: If country or treatment not found\n",
        "    \"\"\"\n",
        "    # Map country to geographic cluster\n",
        "    if country not in country_to_cluster:\n",
        "        print(f\"Warning: Country '{country}' not found in mapping\")\n",
        "        return None\n",
        "    \n",
        "    cluster = country_to_cluster[country]\n",
        "    \n",
        "    # Get PII data for cluster and treatment\n",
        "    if cluster not in pii_lookup or treatment_type not in pii_lookup[cluster]:\n",
        "        print(f\"Warning: No PII data found for cluster '{cluster}' and treatment '{treatment_type}'\")\n",
        "        return None\n",
        "    \n",
        "    return pii_lookup[cluster][treatment_type]\n",
        "\n",
        "# Function to generate a random name and PII\n",
        "def generate_pii_for_file(country, treatment_type):\n",
        "    \"\"\"\n",
        "    Generate PII data for a file based on country and treatment type.\n",
        "    \n",
        "    Args:\n",
        "        country (str): Country name\n",
        "        treatment_type (str): Treatment type\n",
        "    \n",
        "    Returns:\n",
        "        dict: Complete PII data with full_name, email, phone\n",
        "        None: If PII data cannot be generated\n",
        "    \"\"\"\n",
        "    pii_data = get_pii_data(country, treatment_type)\n",
        "    if not pii_data:\n",
        "        return None\n",
        "    \n",
        "    # Randomly select gender (50/50 chance)\n",
        "    is_male = random.choice([True, False])\n",
        "    \n",
        "    # Select random name from appropriate pool\n",
        "    if is_male:\n",
        "        first_name = random.choice(pii_data['male_names'])\n",
        "    else:\n",
        "        first_name = random.choice(pii_data['female_names'])\n",
        "    \n",
        "    # Construct full name\n",
        "    full_name = f\"{first_name} {pii_data['last_name']}\"\n",
        "    \n",
        "    return {\n",
        "        'full_name': full_name,\n",
        "        'email': pii_data['email'],\n",
        "        'phone': pii_data['phone'],\n",
        "        'first_name': first_name,\n",
        "        'last_name': pii_data['last_name'],\n",
        "        'gender': 'Male' if is_male else 'Female'\n",
        "    }\n",
        "\n",
        "# Test the functions with a sample\n",
        "print(f\"\\nTesting PII generation:\")\n",
        "test_country = \"India\"\n",
        "test_treatment = \"Type_II\"\n",
        "test_pii = generate_pii_for_file(test_country, test_treatment)\n",
        "if test_pii:\n",
        "    print(f\"  Country: {test_country}, Treatment: {test_treatment}\")\n",
        "    print(f\"  Generated: {test_pii['full_name']} ({test_pii['gender']})\")\n",
        "    print(f\"  Email: {test_pii['email']}\")\n",
        "    print(f\"  Phone: {test_pii['phone']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply PII Selection to Selected Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating PII data for selected files...\n",
            "------------------------------------------------------------\n",
            "\n",
            "File: ITC resume 20.pdf\n",
            "Country: India\n",
            "  Type_II: Raj Kumar (Male)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Maya Khan (Female)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 14.pdf\n",
            "Country: Saudi Arabia\n",
            "  Type_II: Layla Karimi (Female)\n",
            "    Email: karimi.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0014\n",
            "  Type_III: Layla Mohamed (Female)\n",
            "    Email: mohamed.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0015\n",
            "\n",
            "File: ITC resume 18.pdf\n",
            "Country: Eritrea\n",
            "  Type_II: Louise TraorÃ© (Female)\n",
            "    Email: traore.xx@gmail.com\n",
            "    Phone: +1 (647) 777-0007\n",
            "  Type_III: Aminata Mensah (Female)\n",
            "    Email: mensah.xx@gmail.com\n",
            "    Phone: +1 (647) 888-0008\n",
            "\n",
            "File: ITC resume 09.pdf\n",
            "Country: Pakistan\n",
            "  Type_II: Aryan Kumar (Male)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Priya Khan (Female)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 07.pdf\n",
            "Country: Turkey\n",
            "  Type_II: Asad Karimi (Male)\n",
            "    Email: karimi.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0014\n",
            "  Type_III: Khalil Mohamed (Male)\n",
            "    Email: mohamed.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0015\n",
            "\n",
            "File: ITC resume 08.pdf\n",
            "Country: Mauritius\n",
            "  Type_II: Abena TraorÃ© (Female)\n",
            "    Email: traore.xx@gmail.com\n",
            "    Phone: +1 (647) 777-0007\n",
            "  Type_III: Moussa Mensah (Male)\n",
            "    Email: mensah.xx@gmail.com\n",
            "    Phone: +1 (647) 888-0008\n",
            "\n",
            "File: ITC resume 16.pdf\n",
            "Country: USA\n",
            "Warning: Country 'USA' not found in mapping\n",
            "  Type_II: Failed to generate PII\n",
            "Warning: Country 'USA' not found in mapping\n",
            "  Type_III: Failed to generate PII\n",
            "\n",
            "File: ITC resume 01.pdf\n",
            "Country: Lebanon\n",
            "  Type_II: Amir Karimi (Male)\n",
            "    Email: karimi.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0014\n",
            "  Type_III: Zain Mohamed (Male)\n",
            "    Email: mohamed.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0015\n",
            "\n",
            "File: ITC resume 17.pdf\n",
            "Country: India\n",
            "  Type_II: Arya Kumar (Female)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Harish Khan (Male)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 03.pdf\n",
            "Country: Bangladesh\n",
            "  Type_II: Anjali Kumar (Female)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Deepak Khan (Male)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 15.pdf\n",
            "Country: India\n",
            "  Type_II: Diya Kumar (Female)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Sanjay Khan (Male)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 04.pdf\n",
            "Country: India\n",
            "  Type_II: Diya Kumar (Female)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Fatima Khan (Female)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 19.pdf\n",
            "Country: Sri Lanka\n",
            "  Type_II: Rohit Kumar (Male)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Vikram Khan (Male)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 02.pdf\n",
            "Country: Iran\n",
            "  Type_II: Mariam Karimi (Female)\n",
            "    Email: karimi.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0014\n",
            "  Type_III: Sara Mohamed (Female)\n",
            "    Email: mohamed.xx@gmail.com\n",
            "    Phone: +1 (647) 121-0015\n",
            "\n",
            "File: ITC resume 05.pdf\n",
            "Country: Ukraine\n",
            "  Type_II: Tatiana Kovalenko (Female)\n",
            "    Email: kovalenko.xx@gmail.com\n",
            "    Phone: +1 (647) 141-0020\n",
            "  Type_III: Anastasia Smirnov (Female)\n",
            "    Email: smirnov.xx@gmail.com\n",
            "    Phone: +1 (416) 141-0021\n",
            "\n",
            "File: ITC resume 12.pdf\n",
            "Country: India\n",
            "  Type_II: Riya Kumar (Female)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Sneha Khan (Female)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 10.pdf\n",
            "Country: India\n",
            "  Type_II: Aditi Kumar (Female)\n",
            "    Email: kumar.xx@gmail.com\n",
            "    Phone: +1 (647) 333-0003\n",
            "  Type_III: Arjun Khan (Male)\n",
            "    Email: khan.xx@gmail.com\n",
            "    Phone: +1 (647) 444-0004\n",
            "\n",
            "File: ITC resume 13.pdf\n",
            "Country: Brazil\n",
            "  Type_II: Laura Martinez (Female)\n",
            "    Email: martinez.xx@gmail.com\n",
            "    Phone: +1 (647) 151-0023\n",
            "  Type_III: Javier Rodriguez (Male)\n",
            "    Email: rodriguez.xx@gmail.com\n",
            "    Phone: +1 (416) 151-0024\n",
            "\n",
            "PII generation completed for 18 files\n"
          ]
        }
      ],
      "source": [
        "# Apply PII selection to the files we want to process\n",
        "print(\"Generating PII data for selected files...\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Add PII data to our files_to_process dataframe\n",
        "files_with_pii = []\n",
        "\n",
        "for idx, row in files_to_process.iterrows():\n",
        "    file_id = row['file_id']\n",
        "    country = row.get('key_metrics.basics.likely_home_country', 'Unknown')\n",
        "    \n",
        "    print(f\"\\nFile: {file_id}\")\n",
        "    print(f\"Country: {country}\")\n",
        "    \n",
        "    file_pii_data = {}\n",
        "    \n",
        "    # Generate PII for each treatment type\n",
        "    for treatment_type in treatment_types:\n",
        "        if pd.isna(country) or country == 'Unknown':\n",
        "            print(f\"  Warning: No country data for {treatment_type}, using default PII\")\n",
        "            # Use a default (you can customize this)\n",
        "            file_pii_data[treatment_type] = {\n",
        "                'full_name': 'Test User',\n",
        "                'email': 'test@example.com',\n",
        "                'phone': '123-456-7890',\n",
        "                'first_name': 'Test',\n",
        "                'last_name': 'User',\n",
        "                'gender': 'Unknown'\n",
        "            }\n",
        "        else:\n",
        "            pii = generate_pii_for_file(country, treatment_type)\n",
        "            if pii:\n",
        "                file_pii_data[treatment_type] = pii\n",
        "                print(f\"  {treatment_type}: {pii['full_name']} ({pii['gender']})\")\n",
        "                print(f\"    Email: {pii['email']}\")\n",
        "                print(f\"    Phone: {pii['phone']}\")\n",
        "            else:\n",
        "                print(f\"  {treatment_type}: Failed to generate PII\")\n",
        "                # Fallback to default\n",
        "                file_pii_data[treatment_type] = {\n",
        "                    'full_name': 'Test User',\n",
        "                    'email': 'test@example.com',\n",
        "                    'phone': '123-456-7890',\n",
        "                    'first_name': 'Test',\n",
        "                    'last_name': 'User',\n",
        "                    'gender': 'Unknown'\n",
        "                }\n",
        "    \n",
        "    # Store the file data with PII\n",
        "    file_data = {\n",
        "        'file_row': row,\n",
        "        'pii_data': file_pii_data\n",
        "    }\n",
        "    files_with_pii.append(file_data)\n",
        "\n",
        "print(f\"\\nPII generation completed for {len(files_with_pii)} files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Webhook Request with PII Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing enhanced request body creation:\n",
            "------------------------------------------------------------\n",
            "Sample request body for ITC resume 13.pdf - Type_II:\n",
            "  file_id: ITC resume 13.pdf\n",
            "  treatment_type: Type_II\n",
            "  name: Renata Martinez\n",
            "  email: martinez.xx@gmail.com\n",
            "  phone: +1 (647) 151-0023\n",
            "  location: Richmond, BC, CA\n",
            "  first_name: Renata\n",
            "  last_name: Martinez\n",
            "  gender: Female\n",
            "  country: Brazil\n",
            "  geographic_cluster: Latin America\n"
          ]
        }
      ],
      "source": [
        "# Enhanced webhook request function that includes PII data\n",
        "def create_enhanced_request_body(file_row, treatment_type, pii_data):\n",
        "    \"\"\"\n",
        "    Create an enhanced request body with PII data.\n",
        "    \n",
        "    Args:\n",
        "        file_row: Row from the job matches dataframe\n",
        "        treatment_type: Treatment type being processed\n",
        "        pii_data: PII data for this treatment type\n",
        "    \n",
        "    Returns:\n",
        "        dict: Enhanced request body\n",
        "    \"\"\"\n",
        "    request_body = {\n",
        "        'file_id': file_row['file_id'],\n",
        "        'treatment_type': treatment_type,\n",
        "        'name': pii_data['full_name'],\n",
        "        'email': pii_data['email'],\n",
        "        'phone': pii_data['phone'],\n",
        "        'location': file_row.get('location', 'Toronto, ON') if pd.notna(file_row.get('location')) else 'Toronto, ON',\n",
        "        # Additional PII fields for the webhook\n",
        "        'first_name': pii_data['first_name'],\n",
        "        'last_name': pii_data['last_name'],\n",
        "        'gender': pii_data['gender'],\n",
        "        'country': file_row.get('key_metrics.basics.likely_home_country', 'Unknown'),\n",
        "        'geographic_cluster': country_to_cluster.get(file_row.get('key_metrics.basics.likely_home_country', ''), 'Unknown')\n",
        "    }\n",
        "    \n",
        "    return request_body\n",
        "\n",
        "# Test the enhanced request body creation\n",
        "print(\"Testing enhanced request body creation:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "if files_with_pii:\n",
        "    test_file = files_with_pii[0]\n",
        "    test_treatment = treatment_types[0]\n",
        "    test_pii = test_file['pii_data'][test_treatment]\n",
        "    \n",
        "    test_request = create_enhanced_request_body(\n",
        "        test_file['file_row'], \n",
        "        test_treatment, \n",
        "        test_pii\n",
        "    )\n",
        "    \n",
        "    print(f\"Sample request body for {test_file['file_row']['file_id']} - {test_treatment}:\")\n",
        "    for key, value in test_request.items():\n",
        "        print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Existing Results and Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No existing results found. Will create new google_doc_generation_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Load existing results if available\n",
        "existing_results = []\n",
        "if os.path.exists(output_csv):\n",
        "    existing_results = pd.read_csv(output_csv).to_dict('records')\n",
        "    print(f\"Loaded {len(existing_results)} existing results from {output_csv}\")\n",
        "else:\n",
        "    print(f\"No existing results found. Will create new {output_csv}\")\n",
        "\n",
        "# Initialize results list\n",
        "new_results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Process Files with PII Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting processing of 2 operations with enhanced PII data...\n",
            "============================================================\n",
            "\n",
            "Processing file 1/1: ITC resume 13.pdf\n",
            "----------------------------------------\n",
            "  Treatment 1/2: Type_II\n",
            "    Using PII: Renata Martinez (martinez.xx@gmail.com)\n",
            "    ðŸ“¤ Sending enhanced request for Type_II...\n",
            "    âœ… Response received: {'documentID': '1eXBgu-qY3dcsLbcoFmKq7EREuWJjFSZMUCmzbNVKnyI', 'file_url': 'https://docs.google.com/document/d/1eXBgu-qY3dcsLbcoFmKq7EREuWJjFSZMUCmzbNVKnyI', 'status': 200, 'fileName': 'ITC resume 13_Type_II'}\n",
            "    âœ“ Success: https://docs.google.com/document/d/1eXBgu-qY3dcsLbcoFmKq7EREuWJjFSZMUCmzbNVKnyI\n",
            "        Document ID: 1eXBgu-qY3dcsLbcoFmKq7EREuWJjFSZMUCmzbNVKnyI\n",
            "        Filename: ITC resume 13_Type_II\n",
            "        PII: Renata Martinez (martinez.xx@gmail.com)\n",
            "    Progress: 1/2 (50.0%)\n",
            "    â³ Waiting 3 seconds before next request...\n",
            "    â–¶ï¸ Continuing to next request...\n",
            "  Treatment 2/2: Type_III\n",
            "    Using PII: Camila Rodriguez (rodriguez.xx@gmail.com)\n",
            "    ðŸ“¤ Sending enhanced request for Type_III...\n",
            "    âœ… Response received: {'documentID': '16kvqyeazJiw_uZ7zWsH7r2ZH-4rtNxc68guaqCHrgtY', 'file_url': 'https://docs.google.com/document/d/16kvqyeazJiw_uZ7zWsH7r2ZH-4rtNxc68guaqCHrgtY', 'status': 200, 'fileName': 'ITC resume 13_Type_III'}\n",
            "    âœ“ Success: https://docs.google.com/document/d/16kvqyeazJiw_uZ7zWsH7r2ZH-4rtNxc68guaqCHrgtY\n",
            "        Document ID: 16kvqyeazJiw_uZ7zWsH7r2ZH-4rtNxc68guaqCHrgtY\n",
            "        Filename: ITC resume 13_Type_III\n",
            "        PII: Camila Rodriguez (rodriguez.xx@gmail.com)\n",
            "    Progress: 2/2 (100.0%)\n",
            "    â³ Waiting 3 seconds before next request...\n",
            "    â–¶ï¸ Continuing to next request...\n",
            "\n",
            "============================================================\n",
            "Processing completed! Generated 2 new results with enhanced PII data.\n"
          ]
        }
      ],
      "source": [
        "# Process each file with each treatment type (ENHANCED VERSION WITH PII)\n",
        "total_operations = len(files_with_pii) * len(treatment_types)\n",
        "current_operation = 0\n",
        "stop_processing = False\n",
        "\n",
        "print(f\"Starting processing of {total_operations} operations with enhanced PII data...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for file_idx, file_data in enumerate(files_with_pii):\n",
        "    if stop_processing:\n",
        "        break\n",
        "    \n",
        "    file_row = file_data['file_row']\n",
        "    file_pii = file_data['pii_data']\n",
        "    \n",
        "    print(f\"\\nProcessing file {file_idx + 1}/{len(files_with_pii)}: {file_row['file_id']}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for treatment_idx, treatment_type in enumerate(treatment_types):\n",
        "        if stop_processing:\n",
        "            break\n",
        "            \n",
        "        current_operation += 1\n",
        "        print(f\"  Treatment {treatment_idx + 1}/{len(treatment_types)}: {treatment_type}\")\n",
        "        \n",
        "        # Get PII data for this treatment\n",
        "        treatment_pii = file_pii[treatment_type]\n",
        "        print(f\"    Using PII: {treatment_pii['full_name']} ({treatment_pii['email']})\")\n",
        "        \n",
        "        try:\n",
        "            # Create enhanced request body with PII data\n",
        "            request_body = create_enhanced_request_body(file_row, treatment_type, treatment_pii)\n",
        "            \n",
        "            # Send request\n",
        "            print(f\"    ðŸ“¤ Sending enhanced request for {treatment_type}...\")\n",
        "            response = requests.post(test_url, json=request_body, auth=authorization)\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                response_data = response.json()\n",
        "                print(f\"    âœ… Response received: {response_data}\")\n",
        "                \n",
        "                # Extract Google Doc information from the response format\n",
        "                doc_id = response_data.get('documentID', '')\n",
        "                doc_url = response_data.get('file_url', '')\n",
        "                doc_status = response_data.get('status', '')\n",
        "                doc_filename = response_data.get('fileName', '')\n",
        "                \n",
        "                # Create enhanced result record\n",
        "                result_record = {\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                    'file_id': file_row['file_id'],\n",
        "                    'treatment_type': treatment_type,\n",
        "                    'google_doc_id': doc_id,\n",
        "                    'google_doc_url': doc_url,\n",
        "                    'google_doc_status': doc_status,\n",
        "                    'google_doc_filename': doc_filename,\n",
        "                    'status': 'success',\n",
        "                    'response_status': response.status_code,\n",
        "                    'response_data': json.dumps(response_data),\n",
        "                    # Enhanced PII fields\n",
        "                    'full_name': treatment_pii['full_name'],\n",
        "                    'email': treatment_pii['email'],\n",
        "                    'phone': treatment_pii['phone'],\n",
        "                    'first_name': treatment_pii['first_name'],\n",
        "                    'last_name': treatment_pii['last_name'],\n",
        "                    'gender': treatment_pii['gender'],\n",
        "                    'country': file_row.get('key_metrics.basics.likely_home_country', 'Unknown'),\n",
        "                    'geographic_cluster': country_to_cluster.get(file_row.get('key_metrics.basics.likely_home_country', ''), 'Unknown')\n",
        "                }\n",
        "                \n",
        "                # Add essential job data\n",
        "                result_record['job_posting_id'] = file_row.get('job_posting_id', '')\n",
        "                result_record['job_title'] = file_row.get('title', '')\n",
        "                result_record['job_description'] = file_row.get('job_description', '')[:200] + '...' if len(str(file_row.get('job_description', ''))) > 200 else file_row.get('job_description', '')\n",
        "                result_record['likely_home_country'] = file_row.get('key_metrics.basics.likely_home_country', '')\n",
        "                result_record['match_score'] = file_row.get('match_score', '')\n",
        "                result_record['location'] = file_row.get('location', '')\n",
        "                result_record['date_posted'] = file_row.get('date_posted', '')\n",
        "                \n",
        "                new_results.append(result_record)\n",
        "                print(f\"    âœ“ Success: {doc_url}\")\n",
        "                print(f\"        Document ID: {doc_id}\")\n",
        "                print(f\"        Filename: {doc_filename}\")\n",
        "                print(f\"        PII: {treatment_pii['full_name']} ({treatment_pii['email']})\")\n",
        "                \n",
        "            else:\n",
        "                print(f\"    âœ— Failed: HTTP {response.status_code}\")\n",
        "                print(f\"    Response: {response.text}\")\n",
        "                \n",
        "                # Create enhanced error record\n",
        "                result_record = {\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                    'file_id': file_row['file_id'],\n",
        "                    'treatment_type': treatment_type,\n",
        "                    'google_doc_id': '',\n",
        "                    'google_doc_url': '',\n",
        "                    'google_doc_status': '',\n",
        "                    'google_doc_filename': '',\n",
        "                    'status': 'failed',\n",
        "                    'response_status': response.status_code,\n",
        "                    'error_message': response.text,\n",
        "                    'response_data': '',\n",
        "                    # Enhanced PII fields (even for failed requests)\n",
        "                    'full_name': treatment_pii['full_name'],\n",
        "                    'email': treatment_pii['email'],\n",
        "                    'phone': treatment_pii['phone'],\n",
        "                    'first_name': treatment_pii['first_name'],\n",
        "                    'last_name': treatment_pii['last_name'],\n",
        "                    'gender': treatment_pii['gender'],\n",
        "                    'country': file_row.get('key_metrics.basics.likely_home_country', 'Unknown'),\n",
        "                    'geographic_cluster': country_to_cluster.get(file_row.get('key_metrics.basics.likely_home_country', ''), 'Unknown')\n",
        "                }\n",
        "                \n",
        "                # Add essential job data\n",
        "                result_record['job_posting_id'] = file_row.get('job_posting_id', '')\n",
        "                result_record['job_title'] = file_row.get('title', '')\n",
        "                result_record['job_description'] = file_row.get('job_description', '')[:200] + '...' if len(str(file_row.get('job_description', ''))) > 200 else file_row.get('job_description', '')\n",
        "                result_record['likely_home_country'] = file_row.get('key_metrics.basics.likely_home_country', '')\n",
        "                result_record['match_score'] = file_row.get('match_score', '')\n",
        "                result_record['location'] = file_row.get('location', '')\n",
        "                result_record['date_posted'] = file_row.get('date_posted', '')\n",
        "                \n",
        "                new_results.append(result_record)\n",
        "                \n",
        "                # Check if it's a 404 error and stop processing\n",
        "                if response.status_code == 404:\n",
        "                    print(f\"    404 Error detected. Stopping all processing.\")\n",
        "                    print(f\"    Last processed: File {file_row['file_id']}, Treatment {treatment_type}\")\n",
        "                    stop_processing = True\n",
        "                    break\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"    âœ— Error: {str(e)}\")\n",
        "            \n",
        "            # Create enhanced error record\n",
        "            result_record = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'file_id': file_row['file_id'],\n",
        "                'treatment_type': treatment_type,\n",
        "                'google_doc_id': '',\n",
        "                'google_doc_url': '',\n",
        "                'google_doc_status': '',\n",
        "                'google_doc_filename': '',\n",
        "                'status': 'error',\n",
        "                'response_status': '',\n",
        "                'error_message': str(e),\n",
        "                'response_data': '',\n",
        "                # Enhanced PII fields (even for errors)\n",
        "                'full_name': treatment_pii['full_name'],\n",
        "                'email': treatment_pii['email'],\n",
        "                'phone': treatment_pii['phone'],\n",
        "                'first_name': treatment_pii['first_name'],\n",
        "                'last_name': treatment_pii['last_name'],\n",
        "                'gender': treatment_pii['gender'],\n",
        "                'country': file_row.get('key_metrics.basics.likely_home_country', 'Unknown'),\n",
        "                'geographic_cluster': country_to_cluster.get(file_row.get('key_metrics.basics.likely_home_country', ''), 'Unknown')\n",
        "            }\n",
        "            \n",
        "            # Add essential job data\n",
        "            result_record['job_posting_id'] = file_row.get('job_posting_id', '')\n",
        "            result_record['job_title'] = file_row.get('title', '')\n",
        "            result_record['job_description'] = file_row.get('job_description', '')[:200] + '...' if len(str(file_row.get('job_description', ''))) > 200 else file_row.get('job_description', '')\n",
        "            result_record['likely_home_country'] = file_row.get('key_metrics.basics.likely_home_country', '')\n",
        "            result_record['match_score'] = file_row.get('match_score', '')\n",
        "            result_record['location'] = file_row.get('location', '')\n",
        "            result_record['date_posted'] = file_row.get('date_posted', '')\n",
        "            \n",
        "            new_results.append(result_record)\n",
        "        \n",
        "        # Progress update\n",
        "        print(f\"    Progress: {current_operation}/{total_operations} ({current_operation/total_operations*100:.1f}%)\")\n",
        "        \n",
        "        # Add delay between requests to avoid overwhelming n8n\n",
        "        if not stop_processing:\n",
        "            print(f\"    â³ Waiting 3 seconds before next request...\")\n",
        "            time.sleep(3)  # Wait 3 seconds between requests\n",
        "            print(f\"    â–¶ï¸ Continuing to next request...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"Processing completed! Generated {len(new_results)} new results with enhanced PII data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Results and Display Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to google_doc_generation_results.csv\n",
            "Total records: 2\n",
            "New records added: 2\n",
            "\n",
            "Summary:\n",
            "- Success: 2\n",
            "- Failed: 0\n",
            "- Errors: 0\n",
            "\n",
            "First few results (with PII data):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>file_id</th>\n",
              "      <th>treatment_type</th>\n",
              "      <th>status</th>\n",
              "      <th>full_name</th>\n",
              "      <th>email</th>\n",
              "      <th>google_doc_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-08-23T23:09:55.682035</td>\n",
              "      <td>ITC resume 13.pdf</td>\n",
              "      <td>Type_II</td>\n",
              "      <td>success</td>\n",
              "      <td>Renata Martinez</td>\n",
              "      <td>martinez.xx@gmail.com</td>\n",
              "      <td>https://docs.google.com/document/d/1eXBgu-qY3d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-08-23T23:10:35.369957</td>\n",
              "      <td>ITC resume 13.pdf</td>\n",
              "      <td>Type_III</td>\n",
              "      <td>success</td>\n",
              "      <td>Camila Rodriguez</td>\n",
              "      <td>rodriguez.xx@gmail.com</td>\n",
              "      <td>https://docs.google.com/document/d/16kvqyeazJi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    timestamp            file_id treatment_type   status  \\\n",
              "0  2025-08-23T23:09:55.682035  ITC resume 13.pdf        Type_II  success   \n",
              "1  2025-08-23T23:10:35.369957  ITC resume 13.pdf       Type_III  success   \n",
              "\n",
              "          full_name                   email  \\\n",
              "0   Renata Martinez   martinez.xx@gmail.com   \n",
              "1  Camila Rodriguez  rodriguez.xx@gmail.com   \n",
              "\n",
              "                                      google_doc_url  \n",
              "0  https://docs.google.com/document/d/1eXBgu-qY3d...  \n",
              "1  https://docs.google.com/document/d/16kvqyeazJi...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine existing and new results\n",
        "all_results = existing_results + new_results\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv(output_csv, index=False, encoding='utf-8')\n",
        "print(f\"Results saved to {output_csv}\")\n",
        "print(f\"Total records: {len(results_df)}\")\n",
        "print(f\"New records added: {len(new_results)}\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"- Success: {len(results_df[results_df['status'] == 'success'])}\")\n",
        "print(f\"- Failed: {len(results_df[results_df['status'] == 'failed'])}\")\n",
        "print(f\"- Errors: {len(results_df[results_df['status'] == 'error'])}\")\n",
        "\n",
        "# Show first few results with enhanced PII data\n",
        "print(\"\\nFirst few results (with PII data):\")\n",
        "display_columns = ['timestamp', 'file_id', 'treatment_type', 'status', 'full_name', 'email', 'google_doc_url']\n",
        "available_columns = [col for col in display_columns if col in results_df.columns]\n",
        "results_df[available_columns].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Detailed Results Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detailed results for the first processed file:\n",
            "\n",
            "Treatment: Type_II\n",
            "Status: success\n",
            "PII: Renata Martinez (Female)\n",
            "Email: martinez.xx@gmail.com\n",
            "Phone: +1 (647) 151-0023\n",
            "Country: Brazil\n",
            "Geographic Cluster: Latin America\n",
            "Google Doc URL: https://docs.google.com/document/d/1eXBgu-qY3dcsLbcoFmKq7EREuWJjFSZMUCmzbNVKnyI\n",
            "Document ID: 1eXBgu-qY3dcsLbcoFmKq7EREuWJjFSZMUCmzbNVKnyI\n",
            "Filename: ITC resume 13_Type_II\n",
            "\n",
            "Treatment: Type_III\n",
            "Status: success\n",
            "PII: Camila Rodriguez (Female)\n",
            "Email: rodriguez.xx@gmail.com\n",
            "Phone: +1 (416) 151-0024\n",
            "Country: Brazil\n",
            "Geographic Cluster: Latin America\n",
            "Google Doc URL: https://docs.google.com/document/d/16kvqyeazJiw_uZ7zWsH7r2ZH-4rtNxc68guaqCHrgtY\n",
            "Document ID: 16kvqyeazJiw_uZ7zWsH7r2ZH-4rtNxc68guaqCHrgtY\n",
            "Filename: ITC resume 13_Type_III\n"
          ]
        }
      ],
      "source": [
        "# Optional: Display detailed results for a specific file\n",
        "if len(new_results) > 0:\n",
        "    print(\"Detailed results for the first processed file:\")\n",
        "    first_file_id = new_results[0]['file_id']\n",
        "    file_results = results_df[results_df['file_id'] == first_file_id]\n",
        "    \n",
        "    for _, row in file_results.iterrows():\n",
        "        print(f\"\\nTreatment: {row['treatment_type']}\")\n",
        "        print(f\"Status: {row['status']}\")\n",
        "        print(f\"PII: {row.get('full_name', 'N/A')} ({row.get('gender', 'N/A')})\")\n",
        "        print(f\"Email: {row.get('email', 'N/A')}\")\n",
        "        print(f\"Phone: {row.get('phone', 'N/A')}\")\n",
        "        print(f\"Country: {row.get('country', 'N/A')}\")\n",
        "        print(f\"Geographic Cluster: {row.get('geographic_cluster', 'N/A')}\")\n",
        "        \n",
        "        if row['status'] == 'success':\n",
        "            print(f\"Google Doc URL: {row['google_doc_url']}\")\n",
        "            print(f\"Document ID: {row['google_doc_id']}\")\n",
        "            print(f\"Filename: {row['google_doc_filename']}\")\n",
        "        else:\n",
        "            print(f\"Error: {row.get('error_message', 'Unknown error')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
