# Optimized Resume-to-Job Matching Workflow

This module provides an **optimized workflow** for matching resumes to job postings using MongoDB Vector Search and detailed output with file IDs.

## üöÄ Key Features

### **1. MongoDB Vector Search Integration**
- **Native Vector Search**: Uses MongoDB's built-in vector search capabilities for optimal performance
- **Fallback Support**: Automatically falls back to brute force search if vector index isn't available
- **Index Management**: Includes setup scripts for vector search index creation

### **2. Detailed Output with File IDs**
- **Top 4 Matches Display**: Shows rank, file ID, similarity score, LLM score, and validation status
- **Match Reasoning**: Displays LLM reasoning for the top match
- **Comprehensive Logging**: Detailed logs for debugging and analysis

### **3. Two-Stage Matching Process**
1. **Vector Search**: Find semantically similar resumes using embeddings
2. **LLM Validation**: Use Gemini Pro to validate match quality and assign scores

### **4. Smart Data Storage**
- **Validated Matches**: Stored in `resume_job_matches` collection
- **Unmatched Jobs**: Stored in `unmatched_job_postings` collection with top resume details
- **File ID Tracking**: All outputs include file IDs for easy reference

## üìÅ File Structure

```
Resume Job Matching/
‚îú‚îÄ‚îÄ resume_job_matcher_optimized.py    # Main optimized matcher class
‚îú‚îÄ‚îÄ run_optimized_workflow.py          # Optimized workflow runner
‚îú‚îÄ‚îÄ setup_vector_search.py             # Vector search index setup
‚îú‚îÄ‚îÄ README_OPTIMIZED.md                # This documentation
‚îî‚îÄ‚îÄ test_results/                      # Test outputs and logs
```

## üõ†Ô∏è Setup Instructions

### 1. **Install Dependencies**
```bash
# Activate virtual environment
.venv\Scripts\activate

# Install required packages
pip install pymongo scikit-learn numpy google-generativeai python-dotenv
```

### 2. **Setup Vector Search Index (Optional but Recommended)**
```bash
python setup_vector_search.py
```

This creates the MongoDB vector search index for optimal performance:
```javascript
db.Standardized_resume_data.createIndex({
  'text_embedding': 'vector'
}, {
  'name': 'resume_vector_search',
  'vectorSize': 3072,
  'vectorSearchOptions': {
    'type': 'cosine'
  }
})
```

### 3. **Verify Setup**
```bash
python run_optimized_workflow.py --mode status
```

## üöÄ Usage Examples

### **1. Test Single Job Matching**
```bash
python run_optimized_workflow.py --mode batch --batch-size 1 --max-jobs 1
```

**Sample Output:**
```
============================================================
Processing job 1/1: Software Engineer at TechCorp
Job ID: 68866e1499858055b53daca8
============================================================

Job: Software Engineer at TechCorp
Status: NO_VALID_MATCHES
[FAILED] No valid matches found

Top 4 Resumes Evaluated:
Rank File ID              Similarity   LLM Score    Valid
------------------------------------------------------------
1    MSfE resume 17.pdf   0.721        0            [NO]
2    ITC resume 16.pdf    0.689        0            [NO]
3    CCC resume 03.pdf    0.665        0            [NO]
4    MSfE resume 12.pdf   0.652        0            [NO]

Top Match Reasoning:
The provided resume lacks any information regarding experience, skills, education, or industry. Therefore, it is impossible to assess the candidate's suitability for any job posting.
```

### **2. Batch Processing**
```bash
# Process 10 jobs at a time
python run_optimized_workflow.py --mode batch --batch-size 10

# Process with custom settings
python run_optimized_workflow.py --mode batch --batch-size 5 --max-jobs 20 --delay 2.0
```

### **3. Check Workflow Status**
```bash
python run_optimized_workflow.py --mode status
```

## üìä Collection Schemas

### **resume_job_matches** Collection
```json
{
  "_id": ObjectId,
  
  // References
  "job_posting_id": ObjectId,           // Reference to job_postings
  "resume_id": ObjectId,                // Reference to Standardized_resume_data
  
  // Key job details
  "job_url_direct": string,             // Direct application URL
  "job_title": string,                  // Job title
  "company_name": string,               // Company name
  "job_description_raw": string,        // Full job description
  
  // Key resume details
  "file_id": string,                    // Resume file ID
  "resume_data": object,                // Full resume data
  "key_metrics": object,                // Resume key metrics
  
  // Matching metrics
  "semantic_similarity": float,         // Vector similarity score
  "match_score": float,                 // LLM validation score (0-100)
  "match_reasoning": string,            // LLM reasoning for match
  
  // Status
  "match_status": "VALIDATED",
  "created_at": datetime,
  "validated_at": datetime
}
```

### **unmatched_job_postings** Collection
```json
{
  "_id": ObjectId,
  
  // Reference
  "job_posting_id": ObjectId,           // Reference to job_postings
  
  // Key job details
  "job_url_direct": string,
  "job_title": string,
  "company_name": string,
  "job_description_raw": string,
  
  // Rejection info
  "rejection_reason": string,           // Why no matches found
  "top_similarity_score": float,        // Best similarity score found
  "top_resumes_evaluated": [            // Top resumes that were evaluated
    {
      "file_id": string,
      "similarity_score": float,
      "llm_score": float
    }
  ],
  
  // Timestamps
  "created_at": datetime,
  "scraped_at": datetime
}
```

## ‚öôÔ∏è Configuration Options

### **Workflow Parameters**
- `--batch-size`: Number of jobs to process in each batch (default: 10)
- `--max-jobs`: Maximum total jobs to process (default: all)
- `--delay`: Delay between processing jobs in seconds (default: 1.0)
- `--similarity-threshold`: Minimum similarity for LLM validation (default: 0.3)

### **LLM Validation Thresholds**
- **Match Score ‚â• 70**: Valid match, stored in `resume_job_matches`
- **Match Score < 70**: Invalid match, job stored in `unmatched_job_postings`
- **Similarity < 0.3**: Skip LLM validation, job stored in `unmatched_job_postings`

## üîß Performance Optimization

### **Vector Search vs Brute Force**
- **With Vector Index**: ~10-50x faster than brute force
- **Without Vector Index**: Falls back to brute force with 254 resume comparisons
- **Recommended**: Always set up vector search index for production use

### **Performance Metrics**
- **Processing Speed**: ~4-7 jobs per minute (with LLM validation)
- **Memory Usage**: Optimized for large datasets
- **Scalability**: Supports thousands of jobs and resumes

## üêõ Troubleshooting

### **Common Issues**

1. **Vector Search Index Not Found**
   ```
   WARNING - Vector search index not found. Using fallback brute force search.
   ```
   **Solution**: Run `python setup_vector_search.py`

2. **LLM Validation Errors**
   ```
   Error parsing LLM response: Expecting property name enclosed in double quotes
   ```
   **Solution**: Check Gemini API key and model availability

3. **MongoDB Connection Issues**
   ```
   Failed to connect to MongoDB
   ```
   **Solution**: Verify MongoDB URI and network connectivity

### **Debug Mode**
Enable detailed logging by setting log level:
```python
import logging
logging.getLogger().setLevel(logging.DEBUG)
```

## üìà Monitoring and Analytics

### **Statistics Available**
- Total jobs and resumes with embeddings
- Number of validated matches created
- Number of unmatched jobs
- Processing duration and jobs per minute
- Recent activity in both collections

### **Key Metrics to Monitor**
- **Match Rate**: Percentage of jobs with valid matches
- **Average Match Score**: Quality of matches
- **Processing Speed**: Jobs per minute
- **Error Rate**: Failed processing attempts

## üîÑ Workflow Integration

### **Integration with Existing Workflows**
- **Phase 1**: Uses standardized resume data from extraction workflow
- **Phase 2.1**: Integrates with job scraping and embedding modules
- **Future Phases**: Can be extended for application automation

### **Data Flow**
1. **Input**: Job postings with embeddings + Resumes with embeddings
2. **Processing**: Vector search ‚Üí LLM validation ‚Üí Data storage
3. **Output**: Validated matches + Unmatched jobs with details

## üéØ Best Practices

1. **Always set up vector search index** for optimal performance
2. **Monitor match quality** and adjust LLM thresholds as needed
3. **Regularly check unmatched jobs** to identify data quality issues
4. **Use batch processing** for large datasets to avoid timeouts
5. **Keep detailed logs** for debugging and optimization

## üìù Future Enhancements

- **Multi-modal matching**: Include image-based resume analysis
- **Real-time matching**: Webhook-based processing for new jobs
- **Advanced filtering**: Industry, location, and experience-based filtering
- **Match confidence scoring**: More sophisticated validation algorithms
- **A/B testing**: Compare different matching strategies 